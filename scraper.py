# https://bazaar.abuse.ch/sample/f679205a9b989f7dabf4841813930160412ddce67018b7695e28ce21baa30d8d/
# https://www.virustotal.com/gui/file/4f1ff9bdef6d0b2ece7775e3adae50ac75daeff126faefe81810830d485f934c/details
import time
import requests
import json
import os
from main import url, enable_group_query, queries, rehash, enable_tag_search, enable_keep_tmp_files, \
    clean_response_file, compareHash, groups as grp, nr_of_search_entries as limit, query_using_local_db as local
import csv

cwd = os.getcwd()


def getData():
    x = []
    if enable_group_query:
        searchSigTag()
    if clean_response_file:
        with open('response.json', 'w') as f:
            f.close()
    if local:
        # getHash()
        x = queryHash(getHash())
    return x


def queryHash(hashes):
    count = 0
    # hashes = ['7c2d1f9406d194c8cd18df13efa8ee1385d6531b55b66a989e5b57d4e34149bc']
    with open('response.json', 'a') as f:
        for i in hashes:
            if count == queries:
                print('Queried', count, 'hashes')
                return hashes
            data = {
                'query': 'get_info',
                'hash': i
            }
            try:
                entry = getRes(data, i).json()['data']
                f.write(json.dumps(entry[0]) + '\n')
                hashes.remove(i)
                count += 1
                time.sleep(.5)
            except Exception as e:
                print(f"An error occurred while processing hash {i}: {e}")
                continue
    return hashes


def compareHashes(h):
    print('Comparing hashes versus response.json')
    with open('response.json', 'r') as f:
        for line in f:
            sha = line[17:81]
            if sha in h:
                h.remove(sha)
    return h


def writeHash(hashes):
    with open('hash.txt', 'w', encoding='utf-8') as f:
        for x in hashes:
            f.write(f"{x}\n")
    print('Saved', len(hashes), 'hashes to hash cache')


def getHash():
    hashes = []
    hashCache = str(cwd) + "\\hash.txt"
    if rehash or not os.path.exists(hashCache):
        with open('full.csv', 'r', encoding='utf-8') as db:
            print('Opened local_db.csv for parsing.')
            reader = csv.reader(db)
            for entry in reader:
                try:
                    if entry[8][2:-1] in grp:
                        hashes.append(entry[1][2:-1])
                except:
                    print('Skiping line')
        print('Found:', len(hashes), 'valid sha256 hashes.')
        if compareHash:
            hashes = compareHashes(hashes)
            print('Found:', len(hashes), 'new sha256 hashes.')
        writeHash(hashes)
    else:
        with open('hash.txt', 'r', encoding='utf-8') as f:
            x = f.readlines()
            for l in x:
                hashes.append(l[:-1])
        print('Reading hashes from file hash.txt')
        hashes = compareHashes(hashes)
    return hashes


def searchSigTag():
    getSig()
    entryList = []
    tagList = []
    with open('signature_response.json', 'r') as sig_file:
        for entry in sig_file:
            entryList.append(json.loads(entry))
        if enable_tag_search and enable_group_query:
            getTag()
            with open('tag_response.json', 'r') as tag_file:
                for i in tag_file:
                    tagList.append(json.loads(i))
                for y in tagList:
                    if y not in entryList:
                        entryList.append(y)
    with open('response.json', 'w') as f:
        for x in entryList:
            f.write(json.dumps(x) + '\n')
    if not enable_keep_tmp_files:
        os.remove("tag_response.json")
        os.remove("signature_response.json")


def getTag():
    open('tag_response.json', 'w').close()
    print('Cleaned tag_response.json.')
    for i in grp:
        print('Querying tag:', i)
        data = {
            'query': 'get_taginfo',
            'tag': i,
            'limit': limit
        }
        response = getRes(data, i).json()['data']
        print("Writing tag: ", i, " to file.")
        with open('tag_response.json', 'a') as f:
            for x in response:
                f.write(json.dumps(x) + '\n')
        print("Successfully wrote tag group:", i, " to file.")


def getSig():
    open('signature_response.json', 'w').close()
    print('Cleaned signature_response.json.')
    for i in grp:
        print('Querying group:', i)
        data = {
            'query': 'get_siginfo',
            'signature': i,
            'limit': limit
        }
        response = getRes(data, i).json()['data']
        print("Writing signature group: ", i, "to file.")
        with open('signature_response.json', 'a') as f:
            for x in response:
                f.write(json.dumps(x) + '\n')
        print("Successfully wrote signature group:", i, "to file.")


def getRes(data, i):
    res = requests.post(url, data=data, timeout=20)
    if res.status_code in range(200, 230):
        if data['query'] == 'get_taginfo':
            print("Successfully queried tag for group:", i)
        elif data['query'] == 'get_siginfo':
            print("Successfully queried signature for group:", i)
        elif local:
            print("Success: queried Bazaar found entry matching hash:", i)
        return res
    else:
        pass
